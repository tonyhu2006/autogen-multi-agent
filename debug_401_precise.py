#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç²¾ç¡®å®šä½401é”™è¯¯çš„è°ƒè¯•è„šæœ¬
å¯¹æ¯”ç‹¬ç«‹æµ‹è¯•æˆåŠŸ vs ä¸»ç³»ç»Ÿè¿è¡Œæ—¶å¤±è´¥çš„å·®å¼‚
"""

import os
import sys
import asyncio
import logging
import aiohttp
import json
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# æ¨¡æ‹Ÿä¸»ç³»ç»Ÿçš„ç¯å¢ƒå˜é‡åŠ è½½
load_dotenv('.env.local')
load_dotenv('.env')

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(name)s:%(message)s')
logger = logging.getLogger(__name__)

async def test_independent_api_call():
    """ç‹¬ç«‹APIè°ƒç”¨æµ‹è¯•ï¼ˆå·²çŸ¥æˆåŠŸï¼‰"""
    print("ğŸš€ æµ‹è¯• 1: ç‹¬ç«‹APIè°ƒç”¨ï¼ˆå·²çŸ¥æˆåŠŸï¼‰")
    
    api_key = os.getenv("OPENAI_API_KEY")
    base_url = os.getenv("OPENAI_BASE_URL")
    model = os.getenv("OPENAI_MODEL", "gemini-2.5-flash")
    
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    payload = {
        "model": model,
        "messages": [{"role": "user", "content": "ä½ å¥½"}]
    }
    
    print(f"ğŸ“ URL: {base_url}/v1/chat/completions")
    print(f"ğŸ“‹ API Key (å‰10å­—ç¬¦): {api_key[:10]}...")
    print(f"ğŸ“¦ Model: {model}")
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                f"{base_url}/v1/chat/completions",
                headers=headers,
                json=payload
            ) as response:
                print(f"ğŸ“Š å“åº”çŠ¶æ€: {response.status}")
                
                if response.status == 200:
                    print("âœ… ç‹¬ç«‹APIè°ƒç”¨æˆåŠŸï¼")
                    return True
                else:
                    response_text = await response.text()
                    print(f"âŒ ç‹¬ç«‹APIè°ƒç”¨å¤±è´¥: {response.status}")
                    print(f"ğŸ“ é”™è¯¯å“åº”: {response_text}")
                    return False
                    
    except Exception as e:
        print(f"âŒ ç‹¬ç«‹APIè°ƒç”¨å¼‚å¸¸: {e}")
        return False

async def test_agent_direct_call():
    """æ¨¡æ‹Ÿä»£ç†çš„_direct_gemini_callæ–¹æ³•"""
    print("\nğŸš€ æµ‹è¯• 2: æ¨¡æ‹Ÿä»£ç†_direct_gemini_callæ–¹æ³•")
    
    try:
        # å¯¼å…¥ä»£ç†ç±»
        from agents.base_agent_v4 import create_enhanced_assistant_agent
        from autogen_agentchat.messages import TextMessage
        
        # è·å–ç¯å¢ƒå˜é‡
        api_key = os.getenv("OPENAI_API_KEY")
        base_url = os.getenv("OPENAI_BASE_URL")
        model = os.getenv("OPENAI_MODEL", "gemini-2.5-flash")
        
        print(f"ğŸ“‹ åˆ›å»ºä»£ç†å‰ç¯å¢ƒå˜é‡:")
        print(f"  API Key: '{api_key}' (é•¿åº¦: {len(api_key)})")
        print(f"  Base URL: '{base_url}'")
        print(f"  Model: '{model}'")
        
        # åˆ›å»ºä»£ç†
        agent = await create_enhanced_assistant_agent(
            name="æµ‹è¯•ä»£ç†",
            system_message="ä½ æ˜¯ä¸€ä¸ªæµ‹è¯•ä»£ç†",
            api_key=api_key,
            base_url=base_url,
            model=model
        )
        print("âœ… ä»£ç†åˆ›å»ºæˆåŠŸ")
        
        # æ£€æŸ¥ä»£ç†åˆ›å»ºåçš„ç¯å¢ƒå˜é‡
        api_key_after = os.getenv("OPENAI_API_KEY")
        if api_key != api_key_after:
            print(f"âš ï¸  ä»£ç†åˆ›å»ºåAPI Keyå‘ç”Ÿå˜åŒ–!")
            print(f"  åŸå§‹: '{api_key}'")
            print(f"  ç°åœ¨: '{api_key_after}'")
        
        # åˆ›å»ºæµ‹è¯•æ¶ˆæ¯
        test_message = TextMessage(content="ä½ å¥½", source="user")
        
        # ç›´æ¥è°ƒç”¨_direct_gemini_callæ–¹æ³•
        print("ğŸ“ è°ƒç”¨_direct_gemini_callæ–¹æ³•...")
        result = await agent._direct_gemini_call([test_message])
        
        if result and hasattr(result, 'content') and "æ— æ³•è·å–" not in result.content:
            print(f"âœ… ä»£ç†ç›´æ¥è°ƒç”¨æˆåŠŸ: {result.content[:50]}...")
            return True
        else:
            print(f"âŒ ä»£ç†ç›´æ¥è°ƒç”¨å¤±è´¥: {result.content if result else 'None'}")
            return False
            
    except Exception as e:
        print(f"âŒ ä»£ç†ç›´æ¥è°ƒç”¨å¼‚å¸¸: {e}")
        return False

async def test_system_runtime_simulation():
    """æ¨¡æ‹Ÿä¸»ç³»ç»Ÿè¿è¡Œæ—¶çš„å®Œæ•´ç¯å¢ƒ"""
    print("\nğŸš€ æµ‹è¯• 3: æ¨¡æ‹Ÿä¸»ç³»ç»Ÿè¿è¡Œæ—¶ç¯å¢ƒ")
    
    try:
        # æ¨¡æ‹Ÿä¸»ç³»ç»Ÿçš„å®Œæ•´åˆå§‹åŒ–æµç¨‹
        from teams.team_coordinator_v4 import TeamCoordinator
        from agents.base_agent_v4 import create_enhanced_assistant_agent
        from cognitive_context.protocol_shells import ProtocolShellManager
        from cognitive_context.cognitive_analysis import CognitiveTools
        from autogen_agentchat.messages import TextMessage
        
        # è·å–ç¯å¢ƒå˜é‡
        api_key = os.getenv("OPENAI_API_KEY")
        base_url = os.getenv("OPENAI_BASE_URL")
        model = os.getenv("OPENAI_MODEL", "gemini-2.5-flash")
        
        print(f"ğŸ“‹ ç³»ç»Ÿåˆå§‹åŒ–å‰ç¯å¢ƒå˜é‡:")
        print(f"  API Key: '{api_key}' (é•¿åº¦: {len(api_key)})")
        
        # 1. åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶
        protocol_manager = ProtocolShellManager()
        cognitive_tools = CognitiveTools()
        print("âœ… ç³»ç»Ÿç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
        
        # 2. åˆå§‹åŒ–å›¢é˜Ÿåè°ƒå™¨
        coordinator = TeamCoordinator(
            name="æµ‹è¯•åè°ƒå™¨",
            api_key=api_key,
            base_url=base_url,
            model=model
        )
        print("âœ… å›¢é˜Ÿåè°ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        
        # 3. åˆ›å»ºä»£ç†
        agent = create_enhanced_assistant_agent(
            name="æµ‹è¯•ä»£ç†",
            system_message="ä½ æ˜¯ä¸€ä¸ªæµ‹è¯•ä»£ç†",
            api_key=api_key,
            base_url=base_url,
            model=model
        )
        print("âœ… ä»£ç†åˆ›å»ºå®Œæˆ")
        
        # æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦è¢«ä¿®æ”¹
        api_key_final = os.getenv("OPENAI_API_KEY")
        if api_key != api_key_final:
            print(f"âš ï¸  ç³»ç»Ÿåˆå§‹åŒ–åAPI Keyå‘ç”Ÿå˜åŒ–!")
            print(f"  åŸå§‹: '{api_key}'")
            print(f"  æœ€ç»ˆ: '{api_key_final}'")
        else:
            print("âœ… API Keyåœ¨ç³»ç»Ÿåˆå§‹åŒ–åä¿æŒä¸å˜")
        
        # 4. æµ‹è¯•æ¶ˆæ¯å¤„ç†
        test_message = TextMessage(content="ä½ å¥½", source="user")
        print("ğŸ“ åœ¨å®Œæ•´ç³»ç»Ÿç¯å¢ƒä¸­è°ƒç”¨_direct_gemini_call...")
        
        result = await agent._direct_gemini_call([test_message])
        
        if result and hasattr(result, 'content') and "æ— æ³•è·å–" not in result.content:
            print(f"âœ… ç³»ç»Ÿè¿è¡Œæ—¶è°ƒç”¨æˆåŠŸ: {result.content[:50]}...")
            return True
        else:
            print(f"âŒ ç³»ç»Ÿè¿è¡Œæ—¶è°ƒç”¨å¤±è´¥: {result.content if result else 'None'}")
            return False
            
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿè¿è¡Œæ—¶æ¨¡æ‹Ÿå¼‚å¸¸: {e}")
        return False

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ” ç²¾ç¡®å®šä½401é”™è¯¯è°ƒè¯•")
    print("=" * 60)
    
    # è¿è¡Œä¸‰ä¸ªæµ‹è¯•
    test1_result = await test_independent_api_call()
    test2_result = await test_agent_direct_call()
    test3_result = await test_system_runtime_simulation()
    
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"  ç‹¬ç«‹APIè°ƒç”¨: {'âœ… æˆåŠŸ' if test1_result else 'âŒ å¤±è´¥'}")
    print(f"  ä»£ç†ç›´æ¥è°ƒç”¨: {'âœ… æˆåŠŸ' if test2_result else 'âŒ å¤±è´¥'}")
    print(f"  ç³»ç»Ÿè¿è¡Œæ—¶æ¨¡æ‹Ÿ: {'âœ… æˆåŠŸ' if test3_result else 'âŒ å¤±è´¥'}")
    
    if test1_result and test2_result and test3_result:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½æˆåŠŸï¼é—®é¢˜å¯èƒ½åœ¨äºç‰¹å®šçš„è¿è¡Œæ—¶æ¡ä»¶")
    elif test1_result and not (test2_result or test3_result):
        print("\nğŸ’¡ ç‹¬ç«‹APIè°ƒç”¨æˆåŠŸï¼Œä½†ä»£ç†è°ƒç”¨å¤±è´¥ï¼Œé—®é¢˜åœ¨äºä»£ç†å®ç°")
    elif test1_result and test2_result and not test3_result:
        print("\nğŸ’¡ ä»£ç†è°ƒç”¨æˆåŠŸï¼Œä½†ç³»ç»Ÿè¿è¡Œæ—¶å¤±è´¥ï¼Œé—®é¢˜åœ¨äºç³»ç»Ÿåˆå§‹åŒ–æµç¨‹")
    else:
        print("\nâŒ éœ€è¦è¿›ä¸€æ­¥æ’æŸ¥APIè°ƒç”¨çš„åŸºç¡€é—®é¢˜")

if __name__ == "__main__":
    asyncio.run(main())
